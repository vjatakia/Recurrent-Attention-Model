{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Conv2D, Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config=tf.ConfigProto(gpu_options=gpu_options)\n",
    "\n",
    "config.gpu_options.visible_device_list = \"0\"\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.asarray(mnist.train.images)\n",
    "x_train = np.reshape(x_train,(-1, 28,28,1))\n",
    "y_train = np.asarray(mnist.train.labels)\n",
    "x_test = np.asarray(mnist.test.images)\n",
    "x_test = np.reshape(x_test,(-1, 28,28,1))\n",
    "y_test = np.asarray(mnist.test.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=(10, 10), strides= (5,5), activation='relu', input_shape = input_shape ))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum = 0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 8s 152us/step - loss: 0.2608 - acc: 0.9195\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 7s 119us/step - loss: 0.1069 - acc: 0.9669\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 7s 119us/step - loss: 0.0785 - acc: 0.9751\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 7s 119us/step - loss: 0.0609 - acc: 0.9801\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 7s 121us/step - loss: 0.0518 - acc: 0.9832\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 7s 122us/step - loss: 0.0420 - acc: 0.9864\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 7s 123us/step - loss: 0.0364 - acc: 0.9880\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 7s 123us/step - loss: 0.0320 - acc: 0.9897\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 7s 122us/step - loss: 0.0261 - acc: 0.9912\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 7s 123us/step - loss: 0.0222 - acc: 0.9926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16e49121048>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs= 10,\n",
    "          batch_size=20,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 53us/step\n",
      "Testing Accuracy:  0.977499994993\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size= 20)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f283c2d17b8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFFBJREFUeJzt3Xt0VdWdB/Dvl5AHBFMSBEoTFRS0PkZQUVDaDr7qo1q7WmlVdGiLpZ1qBzpOK9ppV7tqHzpT0VamS1bVMmpFER0ttVWaSjutGokCykMIUIopKVEeolVCQn7zxz059+5Mbu5N7rnnXtjfz1pZ2b+zz73nB8kv++xzzj2HZgYR8cuAQicgIvFT4Yt4SIUv4iEVvoiHVPgiHlLhi3hIhS/iIRW+iIdyKnySF5LcQHITyblRJSUi+cX+XrlHsgTARgDnA2gGsALAlWa2Lt1rylhuFajs1/ZEJLN9+Dv2WxszrTcwh22cAWCTmW0BAJKLAFwGIG3hV6ASk3huDpsUkd40WH1W6+Wyq18L4PWUuDlY5iA5i2QjycZ2tOWwORGJSi6F39PuxP+bN5jZAjObaGYTS1Gew+ZEJCq5FH4zgCNS4joA23NLR0TikEvhrwAwjuQYkmUArgDwZDRpiUg+9fvgnpl1kLwewNMASgDca2ZrI8tMRPIml6P6MLOnADwVUS4iEhNduSfiIRW+iIdU+CIeUuGLeEiFL+IhFb6Ih1T4Ih5S4Yt4SIUv4iEVvoiHcrpkV/xz4OxTw3bJsy8XMBPJhUZ8EQ+p8EU8pMIX8ZDm+NInk+etCNsrJpQUMBPJhUZ8EQ+p8EU8pF39FDuvPdOJh/3s+QJlUjxKqqudeFbNL8P2I4u+7PSNuarbndc6D+QtL8mNRnwRD6nwRTykwhfxUL8fmtkfVayxYnp2XsnYMU78iV82OPGS40fEmU6fsTz5ZCJry8/jyZrumuTEpW8lx4p1n53v9E2483on/sBtz+UlJ0mvweqx13ZlfGimRnwRD6nwRTykwhfxkHfn8VlaFrY3fHuo0/e5qtedeAmKe46/8e6Twva4z76Ul2189/xHnfiBU44L2+ee/kmn75nrb3PiaVtuCNuVj7rHT6SwNOKLeChj4ZO8l2QryTUpy2pILiPZFHyv7u09RKS4ZDydR/IjAN4B8N9mdlKw7DYAu8zshyTnAqg2sxszbazYTucd7Ib9Kfn3dueU3ZG8Z/t5pznxkvt+4sRXHHFW2C45fJjTV/urfU78xr4hYbvtgrecvs597roSjchO55nZHwDs6rb4MgALg/ZCAJ/oc4YiUjD9neOPNLMWAAi+pz0KRnIWyUaSje3Iz0UmItI3eT+4Z2YLzGyimU0sRXnmF4hI3vX3dN4OkqPMrIXkKACtUSYl2YlqXp+q9LfuacHUOX13B97c6cTbJnVf4+8RZXXwar7Z/f/79ZeSpzwX7HI/Bv7CV08P21uvdY+9HTN9ZaR59XfEfxLAjKA9A8AT0aQjInHI5nTeQwCeB3AcyWaSMwH8EMD5JJsAnB/EInKQyLirb2ZXpunSeTmRg5TXH8sVOdToY7kikpYKX8RDKnwRD6nwRTykwhfxkApfxEMqfBEPqfBFPKTCF/GQCl/EQyp8EQ+p8EU8pMIX8ZAKX8RDKnwRD6nwRTykwhfxkApfxEMqfBEPqfBFPKTCF/GQCl/EQyp8EQ+p8EU81N+HZh6SNv5sohNXbCsL28Nf6XD6Bv3Pi7HkJJIPGvFFPJTNQzOPIPksyfUk15KcHSyvIbmMZFPwvTr/6YpIFLIZ8TsA3GBmxwOYDOA6kicAmAug3szGAagPYhE5CGTztNwWAC1B+22S6wHUArgMwNRgtYUAlgO4MS9ZxmTjRXen7Wu3A0581VcvDdv75hzu9NnKtdEmJhKxPs3xSY4GcAqABgAjgz8KXX8cRkSdnIjkR9aFT3IIgCUA5pjZ3j68bhbJRpKN7WjrT44iErGsTueRLEWi6B80s8eCxTtIjjKzFpKjALT29FozWwBgAQBUscYiyDk2G9v3h+3N7cOcvsVjnwrb8x84xun79YlD85uYSI6yOapPAPcAWG9mt6d0PQlgRtCeAeCJ6NMTkXzIZsSfAuAaAK+SXBUsuxnADwE8QnImgG0ApuUnRRGJWjZH9f8IgGm6z402HRGJgy7ZTfGnfaVO/LnlXwzbFVXugcmLzvp52L5syBqn7+kJs5y4c9W6iDIUiYYu2RXxkApfxEMqfBEPHfJz/IF1tU68ZV5N2D5y2qtO31fu/pITl4zoDNsvXPCTbu+c/Mju79872unRnF6KnUZ8EQ+p8EU8dMjt6u+9arIT//R7dzrxiWXJf/IlOM3pq132lhPPWfxo2B7MMqTzl7bD0/aJFCON+CIeUuGLeEiFL+Khg3KOX3Ks+zHY9Tcmb/e39Nx5Tt8HS8ud+EOvJD9LVIXNTt+bp1U58ZkVe1Iid47/TmfyEt5n505x+sqxIk3mIsVBI76Ih1T4Ih6iWXw3xalijU1i8X6Sd9wKd1ow7wPPhe13bb/Td9b8G8J23Q+eg0gxaLB67LVd6T5GH9KIL+IhFb6Ih1T4Ih46KE/n5UvT6e5ddrpf0puqDprXy8FLI76Ih1T4Ih5S4Yt4SIUv4iEVvoiHVPgiHlLhi3hIhS/ioWyelltB8kWSq0muJfmdYPkYkg0km0g+TPZyUzoRKSrZjPhtAM4xs/EAJgC4kORkALcCmGdm4wDsBjAzf2mKSJQyFr4lvBOEpcGXATgHQNdtaBcC+EReMhSRyGU1xydZQnIVgFYAywBsBrDHzDqCVZoB1KZ7vYgUl6wK38wOmNkEAHUAzgBwfE+r9fRakrNINpJsbEdbT6uISMz6dFTfzPYAWA5gMoChJLs+3VcHYHua1ywws4lmNrEU5T2tIiIxy+ao/nCSQ4P2IADnAVgP4FkAlwerzQDwRL6SFJFoZfN5/FEAFpIsQeIPxSNmtpTkOgCLSN4CYCWAe/KYp4hEKGPhm9krAE7pYfkWJOb7InKQOeTuwHPemredeE71xrTrfvziq524c/X6tOsOqKhw4+qhYfvAG286fdbRAZFipkt2RTykwhfxkApfxEOH3Bz/t58/y4nnPJ5+jt/yj9VOPHJ1+vf92+dPdeLGb9wVti8959NO34ENmzKlKVJQGvFFPKTCF/GQCl/EQ4fcHD+T5o73wnbtY39x+no7+37i1evS9u07aqgTl27oV2oisdGIL+IhFb6Ihw65Xf19Iwb12n9t01Vhe2Dztki2uXV6pxOPeyaStxXJG434Ih5S4Yt4SIUv4qFDbo5/w7wHnPjPHfucuHx28hjAgVgykmKx8wtnhu0jr3Evq36tdaQT728rDdu1D5U6fYOb33HizlXpT/UWK434Ih5S4Yt46JDb1T+xrNWJL/rF15x4zNrn40xHisjXv/aLsP2pyt1u5zG9vHCqG27teNeJ73zj7NwS64cXW48K25U/el/Ytobsfr814ot4SIUv4iEVvoiHDrk5/hdn/IsTj1kezZx+f2dJ2j6WuE8P635H3lSd+/al7ZP8+vHNV4Ttb53sjnnV692f4e7jGbbLTt7j9N120mNOPG9UQ9j+1btDnL6PDXZP/fXmPdsfthvaKp2+qRXt7sop2xz7mS+G7f1N2W1LI76Ih1T4Ih5S4Yt4iGY9Pt06L6pYY5N4bmzbE8mHge93L+99a8rosF31e/dS4L1Tx2b/vu8lP95d+UqL0/e9Pyxx4n8oS15GfPL868P21ntux3strxMZZD3ikywhuZLk0iAeQ7KBZBPJh0mWZfteIlJYfdnVn43E47G73ApgnpmNA7AbwMwoExOR/MnqdB7JOgAfA/A9AP9KkgDOAdB1O5uFAL4N4Kd5yDE2T/31ZSeesjr5oIzqy7c7fZ3vupdtij86/rbDiSuXJOPun/isfHRnv7ax49oznfjEMrdU/3PXcWF79H1bwvb2nW1ZvX+2I/4dAL4OoGsSMgzAHjPrujFtM4DaLN9LRAosY+GTvARAq5m9lLq4h1V7PEpIchbJRpKN7cjur5GI5Fc2u/pTAHyc5MUAKgBUIbEHMJTkwGDUrwOwvacXm9kCAAuAxFH9SLIWkZxkLHwzuwnATQBAciqAfzOz6SQXA7gcwCIAMwA8kcc8C6LkvmFhu/NdPQhT8mvgUUeE7btuvsvpK6V7yfjiO88L28NakpelJ2ffvcvlAp4bkTjQtwmJOf89ObyXiMSoTx/SMbPlAJYH7S0Azog+JRHJN12yK+KhQ+5juVEasrgh80oiEXntq8kz4qeXuyfO1u5/z4lr1uV2HYlGfBEPqfBFPKRd/RTHLv6yE4/FCwXKRHzQ9rHTnfjly+elROVO3z/Pnu3Eg557Madta8QX8ZAKX8RDKnwRD2mOn2LsHM3pJT7bLnLH3SFMzuuv/PP5Tt/g36x24lw/9KIRX8RDKnwRDxXNrv6i15/rtb+cyVS7f1KpN5NeusqJh902KGwP+OOqrN9HJAoDDjssbF/z4T86fXs7kw9baf3+0U5feduKaPOI9N1E5KCgwhfxkApfxENFM8cfMqA880r98JHazU68cceRYbv7HVFF8q3p2yeG7aWH/5fTd1nTp8J2+VPRzum704gv4iEVvoiHVPgiHiqaOX6+/Mf73bvofHjSxLD9vqYt3VcXidRbV0924lc+8+Owvbmj3el759a6sF0O96GZUdOIL+IhFb6Ih4pmV/+WN0924s1/H+7Ef553HNL5wncfD9vTD+t9F+mNC5KP8XrfA33JUCSzgbUfcOI533zYiVMvPb9i9TVO3/Bf5/cUXiqN+CIeUuGLeEiFL+KhopnjvzC+tNuSPU40BOkfbvH9U5OXOk7/p7vSrgcAw5/Oz6XB4i8OTJbR+KXNTt+0ITud+MG3R4Ttkd90x93OPOSWjkZ8EQ9lNeKT3ArgbSQ+19JhZhNJ1gB4GMBoAFsBfNrMducnTRGJUl9G/LPNbIKZdV36NhdAvZmNA1AfxCJyEMhljn8ZgKlBeyESj8++Mcd80mPyIYJvTZ/kdDVc/aOUyJ3DP/j2KCeuWZncKenLx3I7P3yKE99xf/IjlR8s7f24wS1vnhS2nxtf1oetykFhfPIak++OuL/XVed/f1rYHrr6+byllEm2I74BeIbkSyRnBctGmlkLAATfR/T0QpKzSDaSbGxHW0+riEjMsh3xp5jZdpIjACwj+Vq2GzCzBQAWAEAVa3K9HbiIRCCrwjez7cH3VpKPAzgDwA6So8ysheQoAK15zBMDBiXvjvu/t87v1pt+V/uWpZ904mPW9u+hGQcGuXf2zbR7n+p3//6hsF2B3B52KIVXcsKxTjxr0RNp1z3h3uucePT9xfHQloy7+iQrSR7W1QbwUQBrADwJYEaw2gwA6f/1IlJUshnxRwJ4nImDawMB/MLMfkNyBYBHSM4EsA3AtF7eQ0SKSMbCN7MtAMb3sHwngHPzkZSI5FfRXLLb3TvT3FN21ddty+p1D7090omPvc+9pkh31pVcvfblaie+dPDetOvWLd/vLrDiOL6tS3ZFPKTCF/GQCl/EQ0U7xx+y2P0YbvviZPsSnNaHd9oQTULirX2XnuHE9Zf+qNsag+NLJiIa8UU8pMIX8VDR7urHofIPwzOvFBhT+XK/t1M7tyls7/xlv99GCmT7FPdy7SMHpt+1T73DDgCU7nVP5xXHyTyN+CJeUuGLeEiFL+Ihr+f4i495Opbt3D+6PmxfjFNj2abE5wc7Twjbz18w2umzlldjziY7GvFFPKTCF/GQ17v6cfnrgXcLnYLk4Oi57k0xL57b23Ttb/lNJiIa8UU8pMIX8ZAKX8RDXs/xP7XpoqzXve/ox524akBF2nXH/maWE3/wK+tSIs33pfA04ot4SIUv4iEVvoiHaDHe9bOKNTaJuiO3SL40WD322i5mWk8jvoiHVPgiHlLhi3hIhS/iIRW+iIdU+CIeivV0Hsk3APwFwOEA3oxtw5kpn94VWz5A8eVULPkcZWYZbx8da+GHGyUbzWxi7BtOQ/n0rtjyAYovp2LLJxPt6ot4SIUv4qFCFf6CAm03HeXTu2LLByi+nIotn14VZI4vIoWlXX0RD8Va+CQvJLmB5CaSc+PcdkoO95JsJbkmZVkNyWUkm4Lv1THmcwTJZ0muJ7mW5OxC5kSyguSLJFcH+XwnWD6GZEOQz8Mky+LIJyWvEpIrSS4tdD4kt5J8leQqko3BsoL9DvVHbIVPsgTAfAAXATgBwJUkT+j9VXnxcwAXdls2F0C9mY0DUB/EcekAcIOZHQ9gMoDrgv+XQuXUBuAcMxsPYAKAC0lOBnArgHlBPrsBzIwpny6zAaxPiQudz9lmNiHlFF4hf4f6zsxi+QJwJoCnU+KbANwU1/a75TIawJqUeAOAUUF7FIANhcgr2P4TAM4vhpwADAbwMoBJSFycMrCnn2UMedQhUUznAFgKgAXOZyuAw7stK/jPqy9fce7q1wJ4PSVuDpYVg5Fm1gIAwfcRGdbPC5KjAZwCoKGQOQW71asAtAJYBmAzgD1m1hGsEvfP7g4AXwfQGcTDCpyPAXiG5Esku+6sWhS/Q9mK8y67Pd0VRKcUAiSHAFgCYI6Z7SUz3kQlb8zsAIAJJIcCeBzA8T2tFkcuJC8B0GpmL5Gc2rW4UPkEppjZdpIjACwj+VqM245EnCN+M4AjUuI6ANtj3H5vdpAcBQDB99Y4N06yFImif9DMHiuGnADAzPYAWI7EsYehJLsGijh/dlMAfJzkVgCLkNjdv6OA+cDMtgffW5H4w3gGiuDn1RdxFv4KAOOCo7FlAK4A8GSM2+/NkwBmBO0ZSMyzY8HE0H4PgPVmdnuhcyI5PBjpQXIQgPOQOKj2LIDL487HzG4yszozG43E78zvzGx6ofIhWUnysK42gI8CWIMC/g71S5wHFABcDGAjEnPGbxTioAaAhwC0AGhHYi9kJhJzxnoATcH3mhjz+RASu6mvAFgVfF1cqJwAnAxgZZDPGgDfCpYfDeBFAJsALAZQXoCf3VQASwuZT7Dd1cHX2q7f40L+DvXnS1fuiXhIV+6JeEiFL+IhFb6Ih1T4Ih5S4Yt4SIUv4iEVvoiHVPgiHvo/VLP+UtmGZ18AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f283c2d17f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = 'mnist_cluttered_train_data.tfrecords'  # address to save the hdf5 file\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    feature = {'train/image': tf.FixedLenFeature([], tf.string),\n",
    "               'train/label': tf.FixedLenFeature([], tf.int64)}\n",
    "   \n",
    "    # Create a list of filenames and pass it to a queue\n",
    "    filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n",
    "    # Define a reader and read the next record\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # Decode the record read by the reader\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    # Convert the image data from string back to the numbers\n",
    "    image = tf.decode_raw(features['train/image'], tf.float32)\n",
    "    \n",
    "    # Cast label data into int32\n",
    "    label = tf.cast(features['train/label'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, (60,60))\n",
    "    \n",
    "    # Any preprocessing here ...\n",
    "    \n",
    "    # Creates batches by randomly shuffling tensors\n",
    "\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    # Initialize all global and local variables\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for batch_index in range(55000):\n",
    "        img, lbl = sess.run([image, label])\n",
    "        train_images.append(img)\n",
    "        train_labels.append(lbl)\n",
    "    # Stop the threads\n",
    "    coord.request_stop()\n",
    "    \n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "\n",
    "plt.imshow(train_images[0])\n",
    "\n",
    "data_path = 'mnist_cluttered_test_data.tfrecords'  # address to save the hdf5 file\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    feature = {'test/image': tf.FixedLenFeature([], tf.string),\n",
    "               'test/label': tf.FixedLenFeature([], tf.int64)}\n",
    "   \n",
    "    # Create a list of filenames and pass it to a queue\n",
    "    filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n",
    "    # Define a reader and read the next record\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # Decode the record read by the reader\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    # Convert the image data from string back to the numbers\n",
    "    image = tf.decode_raw(features['test/image'], tf.float32)\n",
    "    \n",
    "    # Cast label data into int32\n",
    "    label = tf.cast(features['test/label'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, (60,60))\n",
    "    \n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "# Initialize all global and local variables\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for batch_index in range(10000):\n",
    "        img, lbl = sess.run([image, label])\n",
    "        test_images.append(img)\n",
    "        test_labels.append(lbl)\n",
    "    # Stop the threads\n",
    "    coord.request_stop()\n",
    "    \n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "\n",
    "plt.imshow(test_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onehot_train_labels = np.zeros((55000, 10))\n",
    "onehot_train_labels[np.arange(55000), train_labels] = 1\n",
    "\n",
    "\n",
    "onehot_test_labels = np.zeros((10000, 10))\n",
    "onehot_test_labels[np.arange(10000), test_labels] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.asarray(train_images)\n",
    "x_train = np.reshape(x_train,(-1, 60, 60,1))\n",
    "y_train = np.asarray(train_labels)\n",
    "x_test = np.asarray(test_images)\n",
    "x_test = np.reshape(x_test,(-1, 60,60,1))\n",
    "y_test = np.asarray(test_labels)\n",
    "\n",
    "input_shape = (60, 60, 1)\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=(10, 10), strides= (5,5), activation='relu', input_shape = input_shape ))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum = 0.9),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 9s 159us/step - loss: 2.1883 - acc: 0.1833\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 1.8077 - acc: 0.3484\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 9s 162us/step - loss: 1.3824 - acc: 0.5130\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 9s 160us/step - loss: 1.1010 - acc: 0.6169\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 9s 156us/step - loss: 0.8964 - acc: 0.6877\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 9s 155us/step - loss: 0.7316 - acc: 0.7469\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 8s 153us/step - loss: 0.5955 - acc: 0.7947\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 8s 152us/step - loss: 0.4954 - acc: 0.8281\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 8s 153us/step - loss: 0.4154 - acc: 0.8566\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 8s 153us/step - loss: 0.3695 - acc: 0.8723\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 8s 153us/step - loss: 0.3187 - acc: 0.8905\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.2944 - acc: 0.8997\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 8s 151us/step - loss: 0.2667 - acc: 0.9087\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 8s 152us/step - loss: 0.2551 - acc: 0.9149\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 8s 152us/step - loss: 0.2257 - acc: 0.9247\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 9s 165us/step - loss: 0.2133 - acc: 0.9286\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 9s 166us/step - loss: 0.2165 - acc: 0.9299\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 9s 159us/step - loss: 0.1917 - acc: 0.9374\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.1847 - acc: 0.9411\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 9s 158us/step - loss: 0.1903 - acc: 0.9400\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 9s 156us/step - loss: 0.1812 - acc: 0.9433\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 8s 153us/step - loss: 0.1886 - acc: 0.9414\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 9s 155us/step - loss: 0.1938 - acc: 0.9422\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 8s 154us/step - loss: 0.1742 - acc: 0.9477\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 8s 154us/step - loss: 0.1834 - acc: 0.9457\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f27c4676eb8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, onehot_train_labels,\n",
    "          epochs= 25,\n",
    "          batch_size=20,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 83us/step\n",
      "Testing Accuracy:  0.5481000005304814\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = model.evaluate(x_test, onehot_test_labels, batch_size= 20)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f283414ed30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f275077c2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = 'mnist_shifted_train_data.tfrecords'  # address to save the hdf5 file\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    feature = {'train/image': tf.FixedLenFeature([], tf.string),\n",
    "               'train/label': tf.FixedLenFeature([], tf.int64)}\n",
    "   \n",
    "    # Create a list of filenames and pass it to a queue\n",
    "    filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n",
    "    # Define a reader and read the next record\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # Decode the record read by the reader\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    # Convert the image data from string back to the numbers\n",
    "    image = tf.decode_raw(features['train/image'], tf.float32)\n",
    "    \n",
    "    # Cast label data into int32\n",
    "    label = tf.cast(features['train/label'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, (60,60))\n",
    "    \n",
    "    # Any preprocessing here ...\n",
    "    \n",
    "    # Creates batches by randomly shuffling tensors\n",
    "\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    # Initialize all global and local variables\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for batch_index in range(55000):\n",
    "        img, lbl = sess.run([image, label])\n",
    "        train_images.append(img)\n",
    "        train_labels.append(lbl)\n",
    "    # Stop the threads\n",
    "    coord.request_stop()\n",
    "    \n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "\n",
    "plt.imshow(train_images[0])\n",
    "\n",
    "data_path = 'mnist_shifted_test_data.tfrecords'  # address to save the hdf5 file\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    feature = {'test/image': tf.FixedLenFeature([], tf.string),\n",
    "               'test/label': tf.FixedLenFeature([], tf.int64)}\n",
    "   \n",
    "    # Create a list of filenames and pass it to a queue\n",
    "    filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n",
    "    # Define a reader and read the next record\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # Decode the record read by the reader\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    # Convert the image data from string back to the numbers\n",
    "    image = tf.decode_raw(features['test/image'], tf.float32)\n",
    "    \n",
    "    # Cast label data into int32\n",
    "    label = tf.cast(features['test/label'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, (60,60))\n",
    "    \n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "# Initialize all global and local variables\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for batch_index in range(10000):\n",
    "        img, lbl = sess.run([image, label])\n",
    "        test_images.append(img)\n",
    "        test_labels.append(lbl)\n",
    "    # Stop the threads\n",
    "    coord.request_stop()\n",
    "    \n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(test_images[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onehot_train_labels = np.zeros((55000, 10))\n",
    "onehot_train_labels[np.arange(55000), train_labels] = 1\n",
    "\n",
    "\n",
    "onehot_test_labels = np.zeros((10000, 10))\n",
    "onehot_test_labels[np.arange(10000), test_labels] = 1\n",
    "\n",
    "x_train = np.asarray(train_images)\n",
    "x_train = np.reshape(x_train,(-1, 60, 60,1))\n",
    "y_train = np.asarray(train_labels)\n",
    "x_test = np.asarray(test_images)\n",
    "x_test = np.reshape(x_test,(-1, 60,60,1))\n",
    "y_test = np.asarray(test_labels)\n",
    "\n",
    "input_shape = (60, 60, 1)\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, kernel_size=(10, 10), strides= (5,5), activation='relu', input_shape = input_shape ))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum = 0.9),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 9s 156us/step - loss: 1.8162 - acc: 0.3345\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 9s 155us/step - loss: 1.0258 - acc: 0.6473\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 8s 153us/step - loss: 0.7224 - acc: 0.7612\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 8s 153us/step - loss: 0.5719 - acc: 0.8112\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 8s 153us/step - loss: 0.4789 - acc: 0.8400\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 8s 153us/step - loss: 0.4018 - acc: 0.8652\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 8s 154us/step - loss: 0.3475 - acc: 0.8822\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 8s 154us/step - loss: 0.3068 - acc: 0.8957\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 8s 154us/step - loss: 0.2600 - acc: 0.9107\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 8s 152us/step - loss: 0.2358 - acc: 0.9196\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 8s 152us/step - loss: 0.2050 - acc: 0.9303\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 8s 150us/step - loss: 0.1800 - acc: 0.9383\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.1667 - acc: 0.9446\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 8s 148us/step - loss: 0.1546 - acc: 0.9477\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 8s 149us/step - loss: 0.1427 - acc: 0.9526\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 8s 150us/step - loss: 0.1419 - acc: 0.9530\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 9s 155us/step - loss: 0.1334 - acc: 0.9562\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 8s 152us/step - loss: 0.1179 - acc: 0.9609\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 8s 144us/step - loss: 0.1164 - acc: 0.9623\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 8s 147us/step - loss: 0.1164 - acc: 0.9631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f27006ed0b8>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(x_train, onehot_train_labels,\n",
    "          epochs= 20,\n",
    "          batch_size=20,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 96us/step\n",
      "Testing Accuracy:  0.7990000002384186\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = model.evaluate(x_test, onehot_test_labels, batch_size= 20)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f26a32d7a58>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f26a3423a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[89])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
