{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "\n",
    "# Generate dummy data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = mnist.train.images\n",
    "y_train = mnist.train.labels\n",
    "x_test = mnist.test.images\n",
    "y_test = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Dense(256) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(256, activation='relu', input_dim= 784))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#decay=1e-6\n",
    "sgd = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 8s 150us/step - loss: 0.5170 - acc: 0.8648\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 7s 120us/step - loss: 0.2497 - acc: 0.9286\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 7s 121us/step - loss: 0.1979 - acc: 0.9433\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 7s 120us/step - loss: 0.1642 - acc: 0.9531\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 7s 121us/step - loss: 0.1406 - acc: 0.9597\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 7s 121us/step - loss: 0.1217 - acc: 0.9656\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 7s 124us/step - loss: 0.1073 - acc: 0.9695\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 7s 125us/step - loss: 0.0948 - acc: 0.9733\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 7s 131us/step - loss: 0.0851 - acc: 0.9763\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 0.0764 - acc: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb7aab780b8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs= 10,\n",
    "          batch_size=20,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 47us/step\n",
      "Testing Accuracy:  0.972799995065\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size= 20)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'mnist_cluttered_train_data.tfrecords'  # address to save the hdf5 file\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    feature = {'train/image': tf.FixedLenFeature([], tf.string),\n",
    "               'train/label': tf.FixedLenFeature([], tf.int64)}\n",
    "   \n",
    "    # Create a list of filenames and pass it to a queue\n",
    "    filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n",
    "    # Define a reader and read the next record\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # Decode the record read by the reader\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    # Convert the image data from string back to the numbers\n",
    "    image = tf.decode_raw(features['train/image'], tf.float32)\n",
    "    \n",
    "    # Cast label data into int32\n",
    "    label = tf.cast(features['train/label'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, (60,60))\n",
    "    \n",
    "    # Any preprocessing here ...\n",
    "    \n",
    "    # Creates batches by randomly shuffling tensors\n",
    "\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    # Initialize all global and local variables\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for batch_index in range(55000):\n",
    "        img, lbl = sess.run([image, label])\n",
    "        train_images.append(img)\n",
    "        train_labels.append(lbl)\n",
    "    # Stop the threads\n",
    "    coord.request_stop()\n",
    "    \n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb7900d6898>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7a7fc3d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'mnist_cluttered_test_data.tfrecords'  # address to save the hdf5 file\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    feature = {'test/image': tf.FixedLenFeature([], tf.string),\n",
    "               'test/label': tf.FixedLenFeature([], tf.int64)}\n",
    "   \n",
    "    # Create a list of filenames and pass it to a queue\n",
    "    filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n",
    "    # Define a reader and read the next record\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # Decode the record read by the reader\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    # Convert the image data from string back to the numbers\n",
    "    image = tf.decode_raw(features['test/image'], tf.float32)\n",
    "    \n",
    "    # Cast label data into int32\n",
    "    label = tf.cast(features['test/label'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, (60,60))\n",
    "    \n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "# Initialize all global and local variables\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for batch_index in range(10000):\n",
    "        img, lbl = sess.run([image, label])\n",
    "        test_images.append(img)\n",
    "        test_labels.append(lbl)\n",
    "    # Stop the threads\n",
    "    coord.request_stop()\n",
    "    \n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb78069f9e8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7806b94e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_train_images = []\n",
    "for i in range(55000):\n",
    "    flat_train_images.append(np.reshape(train_images[i], (3600,)))\n",
    "\n",
    "flat_test_images = []\n",
    "for i in range(10000):\n",
    "    flat_test_images.append(np.reshape(test_images[i], (3600,)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "onehot_train_labels = np.zeros((55000, 10))\n",
    "onehot_train_labels[np.arange(55000), train_labels] = 1\n",
    "\n",
    "\n",
    "onehot_test_labels = np.zeros((10000, 10))\n",
    "onehot_test_labels[np.arange(10000), test_labels] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_train_images = np.asarray(flat_train_images)\n",
    "flat_test_images = np.asarray(flat_test_images)\n",
    "onehot_train_labels = np.asarray(onehot_train_labels)\n",
    "onehot_test_labels = np.asarray(onehot_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = flat_train_images\n",
    "y_train = onehot_train_labels\n",
    "x_test = flat_test_images\n",
    "y_test = onehot_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Dense(256) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(256, activation='relu', input_dim= 3600))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#decay=1e-6\n",
    "sgd = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "55000/55000 [==============================] - 8s 137us/step - loss: 2.2926 - acc: 0.1332\n",
      "Epoch 2/20\n",
      "55000/55000 [==============================] - 8s 140us/step - loss: 2.2129 - acc: 0.1998\n",
      "Epoch 3/20\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 2.1217 - acc: 0.2381\n",
      "Epoch 4/20\n",
      "55000/55000 [==============================] - 7s 127us/step - loss: 2.0172 - acc: 0.2861\n",
      "Epoch 5/20\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 1.8874 - acc: 0.3388\n",
      "Epoch 6/20\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 1.7298 - acc: 0.4004\n",
      "Epoch 7/20\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 1.5531 - acc: 0.4645\n",
      "Epoch 8/20\n",
      "55000/55000 [==============================] - 7s 122us/step - loss: 1.3702 - acc: 0.5319\n",
      "Epoch 9/20\n",
      "55000/55000 [==============================] - 7s 125us/step - loss: 1.1848 - acc: 0.5974\n",
      "Epoch 10/20\n",
      "55000/55000 [==============================] - 7s 125us/step - loss: 1.0080 - acc: 0.6609\n",
      "Epoch 11/20\n",
      "55000/55000 [==============================] - 7s 125us/step - loss: 0.8383 - acc: 0.7203\n",
      "Epoch 12/20\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 0.6807 - acc: 0.7766\n",
      "Epoch 13/20\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 0.5420 - acc: 0.8257\n",
      "Epoch 14/20\n",
      "55000/55000 [==============================] - 7s 124us/step - loss: 0.4158 - acc: 0.8724\n",
      "Epoch 15/20\n",
      "55000/55000 [==============================] - 7s 123us/step - loss: 0.3135 - acc: 0.9099\n",
      "Epoch 16/20\n",
      "55000/55000 [==============================] - 7s 124us/step - loss: 0.2238 - acc: 0.9431\n",
      "Epoch 17/20\n",
      "55000/55000 [==============================] - 7s 125us/step - loss: 0.1470 - acc: 0.9695\n",
      "Epoch 18/20\n",
      "55000/55000 [==============================] - 7s 127us/step - loss: 0.0869 - acc: 0.9893\n",
      "Epoch 19/20\n",
      "55000/55000 [==============================] - 7s 133us/step - loss: 0.0473 - acc: 0.9976\n",
      "Epoch 20/20\n",
      "55000/55000 [==============================] - 8s 137us/step - loss: 0.0285 - acc: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb71003a278>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs= 20,\n",
    "          batch_size=20,\n",
    "          verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 77us/step\n",
      "Testing Accuracy:  0.34140000205487014\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size= 20)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb79cec1cc0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb7a80079b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = 'mnist_shifted_train_data.tfrecords'  # address to save the hdf5 file\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    feature = {'train/image': tf.FixedLenFeature([], tf.string),\n",
    "               'train/label': tf.FixedLenFeature([], tf.int64)}\n",
    "   \n",
    "    # Create a list of filenames and pass it to a queue\n",
    "    filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n",
    "    # Define a reader and read the next record\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # Decode the record read by the reader\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    # Convert the image data from string back to the numbers\n",
    "    image = tf.decode_raw(features['train/image'], tf.float32)\n",
    "    \n",
    "    # Cast label data into int32\n",
    "    label = tf.cast(features['train/label'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, (60,60))\n",
    "    \n",
    "    # Any preprocessing here ...\n",
    "    \n",
    "    # Creates batches by randomly shuffling tensors\n",
    "\n",
    "    train_images = []\n",
    "    train_labels = []\n",
    "    # Initialize all global and local variables\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for batch_index in range(55000):\n",
    "        img, lbl = sess.run([image, label])\n",
    "        train_images.append(img)\n",
    "        train_labels.append(lbl)\n",
    "    # Stop the threads\n",
    "    coord.request_stop()\n",
    "    \n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "\n",
    "plt.imshow(train_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb6b076b278>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb71005cd68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_path = 'mnist_shifted_test_data.tfrecords'  # address to save the hdf5 file\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:\n",
    "    feature = {'test/image': tf.FixedLenFeature([], tf.string),\n",
    "               'test/label': tf.FixedLenFeature([], tf.int64)}\n",
    "   \n",
    "    # Create a list of filenames and pass it to a queue\n",
    "    filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n",
    "    # Define a reader and read the next record\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # Decode the record read by the reader\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    # Convert the image data from string back to the numbers\n",
    "    image = tf.decode_raw(features['test/image'], tf.float32)\n",
    "    \n",
    "    # Cast label data into int32\n",
    "    label = tf.cast(features['test/label'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, (60,60))\n",
    "    \n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "# Initialize all global and local variables\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for batch_index in range(10000):\n",
    "        img, lbl = sess.run([image, label])\n",
    "        test_images.append(img)\n",
    "        test_labels.append(lbl)\n",
    "    # Stop the threads\n",
    "    coord.request_stop()\n",
    "    \n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n",
    "    sess.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.imshow(test_images[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_train_images = []\n",
    "for i in range(55000):\n",
    "    flat_train_images.append(np.reshape(train_images[i], (3600,)))\n",
    "\n",
    "flat_test_images = []\n",
    "for i in range(10000):\n",
    "    flat_test_images.append(np.reshape(test_images[i], (3600,)))\n",
    "    \n",
    "\n",
    "\n",
    "onehot_train_labels = np.zeros((55000, 10))\n",
    "onehot_train_labels[np.arange(55000), train_labels] = 1\n",
    "\n",
    "\n",
    "onehot_test_labels = np.zeros((10000, 10))\n",
    "onehot_test_labels[np.arange(10000), test_labels] = 1\n",
    "\n",
    "\n",
    "onehot_train_labels.shape\n",
    "\n",
    "flat_train_images = np.asarray(flat_train_images)\n",
    "flat_test_images = np.asarray(flat_test_images)\n",
    "onehot_train_labels = np.asarray(onehot_train_labels)\n",
    "onehot_test_labels = np.asarray(onehot_test_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = flat_train_images\n",
    "y_train = onehot_train_labels\n",
    "x_test = flat_test_images\n",
    "y_test = onehot_test_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Dense(256) is a fully-connected layer with 64 hidden units.\n",
    "# in the first layer, you must specify the expected input data shape:\n",
    "# here, 20-dimensional vectors.\n",
    "model.add(Dense(256, activation='relu', input_dim= 3600))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "#decay=1e-6\n",
    "sgd = SGD(lr=0.001, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 7s 131us/step - loss: 2.2641 - acc: 0.1622\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 7s 134us/step - loss: 2.0965 - acc: 0.2476\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 7s 131us/step - loss: 1.9540 - acc: 0.3033\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 1.7715 - acc: 0.3880\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 7s 124us/step - loss: 1.5015 - acc: 0.4941\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 1.2292 - acc: 0.5881\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 7s 124us/step - loss: 1.0159 - acc: 0.6626\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 7s 130us/step - loss: 0.8577 - acc: 0.7135\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 7s 127us/step - loss: 0.7280 - acc: 0.7615\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 0.6205 - acc: 0.7989\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 0.5236 - acc: 0.8330\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 7s 131us/step - loss: 0.4403 - acc: 0.8607\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 7s 133us/step - loss: 0.3666 - acc: 0.8896\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 7s 134us/step - loss: 0.2998 - acc: 0.9123\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 7s 130us/step - loss: 0.2433 - acc: 0.9323\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 7s 129us/step - loss: 0.1925 - acc: 0.9510\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 7s 129us/step - loss: 0.1478 - acc: 0.9663\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 7s 126us/step - loss: 0.1123 - acc: 0.9787\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 0.0812 - acc: 0.9882\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 7s 125us/step - loss: 0.0590 - acc: 0.9942\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 7s 123us/step - loss: 0.0426 - acc: 0.9979\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 7s 124us/step - loss: 0.0325 - acc: 0.9990\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 7s 128us/step - loss: 0.0258 - acc: 0.9994\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 7s 132us/step - loss: 0.0212 - acc: 0.9997\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 7s 131us/step - loss: 0.0180 - acc: 0.9998\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 7s 133us/step - loss: 0.0158 - acc: 0.9999\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 7s 133us/step - loss: 0.0141 - acc: 0.9999\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 7s 134us/step - loss: 0.0127 - acc: 0.9999\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 7s 132us/step - loss: 0.0115 - acc: 0.9999\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 7s 132us/step - loss: 0.0106 - acc: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb7a7ff00f0>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs= 30, batch_size=20, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 64us/step\n",
      "Testing Accuracy:  0.7016000008583069\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score = model.evaluate(x_test, y_test, batch_size= 20)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
